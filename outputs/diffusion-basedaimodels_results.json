{
  "status": "success",
  "media_file": "https://youtu.be/Yu4ZWy1GjlE?si=mVMNqzOOPhx1ioS1",
  "audio_file": "/var/folders/g1/nd4gy981295dn1ts1pjcb61c0000gn/T/media_knowledge_977grzqy/Diffusion_Models_Just_Beat_Large_Language_Models_youtube.wav",
  "transcript": "In today's video, we'll see what diffusion based models are. These are quickly replacing large language models for most tasks, code generation, image generation, video generation. By the end of this video, you'll know what a diffusion based model is, how it's useful, and the internal mechanism that is used by a model like this. So let's start. To understand diffusion based models, let's see how they generate output. An input query might be what is the best programming language in 2026. And if you have a large language model, it might say in terms of popularity, I would say Python. Here, the large model is going to be generating tokens one by one from left to right. But if you would consider something else, some other feature, let's say speed, then maybe you would say rust or go. Which means that the final output, the tokens which come after popularity, completely depend on the fact that you have chosen popularity. But if we pass the same input to a diffusion based model, then it's going to generate a bunch of tokens. The diffusion model now can iteratively improve on this output by replacing some of the tokens. So in terms of speed can change to in terms of safety, I choose C++. And it can refine its answer even further by adding tokens of end speed. If it were a large language model, after generating the token of safety, you would have no choice but to follow through on that initial thought. But for a diffusion based model, there is no such constraint. It can generate text by going back and forth until you have something which is acceptable. Why is this so useful? Think about images where you are generating an image. If you go from left to right while generating an image, it's quite likely that you have made a mistake over here or you have made a mistake over here. But in an auto-regressive model, you can't really improve this. In a auto-regressive model, you can't really improve this. In case of a diffusion based model, since the entire image is constantly being bubbled, is being improved, you can improve the image till it becomes acceptable. So this is the behavior of a diffusion based model. But why is it getting so popular? Is it really better than a large language model? In many cases, no. Large language models or auto-regressive models especially have the benefit that they require lesser compute. So if you're buying many NVIDIA GPUs and you're almost out of budget, it makes sense to go for an auto-regressive model which is going to require lesser compute than a diffusion based model. However, at this point in time when it comes to 2025 or beyond, it looks like the major bottleneck for scaling models is not compute but data. Data is being called the fossil fuel of the world in the sense that you can only generate so much data and it takes a long time to generate. Getting information out of this data is even more challenging because a lot of the data is repeated. For example, if I have weather forecasts and I give you the weather forecast of 37 degrees, 38 degrees, 30 degrees, 31 degrees, then all of this data just gives me the information that this place is a hot place. The amount of data that we have in the world is low. The amount that we are generating is also not a lot. We are able to compute a lot more than we are generating. And the amount of information that you have with all this data is limited, is low. Knowing this, diffusion based models have a clear advantage. One of the things is for the same amount of data, diffusion models outperform auto-regressive models. The other thing is if you pass in the data again and again during training, if you pass it in four times for auto-regressive model, then it almost feels like fresh data to the auto-regressive model. The reason is once you pass this data through your neural network, it's going to update its weights. The second time you pass in the data, some of the weights may be inaccurate or incorrect or may have been changed too much. So you have epoch 1, then you have epoch 2, till you have epoch 4. So the same data can be reused, just sent in again, duplicates. On the other hand, you have the diffusion based model, which can have duplicates 100 times, not four times, 100 times. This is the primary reason that as an AI engineer, you are interested in a diffusion based model. You have a lack of data. And so to get the most ROI for the limited data that you have, you're looking at diffusion. Let's see how diffusion based models actually work. Firstly, you have some sort of an input, which might be images or code or video, to the model. The model maps this input into a vector. So if it's an image, it will be an image vector. If it's a video, it will be a video vector, and so on. The vector then is basically a mapping in an n dimensional space. The model takes the original input and then adds some noise to it, which takes the vector to a new position. Let's say this is v1. This is going to be v2 for the noisy image. You can then add more noise to it to take it to a new position v3. And in this way, you keep adding noise till the original input is almost completely distorted. There's very little information to be had. If there's very little information to be had, then there is very little meaning to that vector, which you can map in the vector space. So you get a bunch of vectors by adding more and more noise. In fact, to be more precise, you take the original image v1, and then you map it to multiple vectors here, nearby. Then you take the noisy image, the first layer of noise images, and then you add more noise to them, which means they're getting further and further away from the first most meaningful image. And you get this vector space with a single image, which has high value here, close to reality, slightly lower value here, here, here, here, and here, and much lower value here, here, here, and here. So the first original image has a very high value. You can say it has a score of 1,000. The second one has a score of 100. The third one, the third level of noise image, has a score of 10. And maybe the fourth level has a score of 1. This is for one image. Another image might come in here, which makes this point a high value point. You can think of a new school coming in a neighborhood. The price of everything in that place increases. And similarly, in the diffusion-based model, if a new sample comes in there, you know that there is some reality, which this vector is actually representing. So all the points near that place, after adding noise to them, have added value. In a three-dimensional space, these will be mountains. These will be smaller hills. And these will be little mounds. Everything else is flat. And your job, whenever you're dropped into this 3D space, is to find the tallest mountain that you can see. So the diffusion-based model has many, many images, hundreds of thousands of images, that are fed into it. It then generates this complex n-dimensional space, where high values are represented by direct vectors. And the value keeps reducing as you add more and more noise to the original images. Now, there are two questions which come here. One is, how are you generating these vectors? How do you know that this vector should land here? And the next image, the noisy image, is going to land here. So what gives you the coordinates of an image into a vector space? That's one big question. And the second question is, using this diffusion-based model, what can we really do? That is an easy answer. We can generate output. If it's an image-based diffusion model, then you can generate images. If it's a coding-based diffusion model, then you can generate code and so on. Given an input query that generates the code for sorting, you're going to take that original input query, code for sorting. You're going to convert this into a vector that will send you somewhere in this n-dimensional space. From here, you look around at the tallest mountains that you can see and choose the tallest mountain. So here, you're doing some sort of a random walk or a gradient descent till you reach the end state, the goal state, the tallest mountain that you can see in this vector space. So generating text or generating any kind of output is intuitive. We know that the highest value space should be where we should go for. We are being nudged into that space with the input query. So that's also good. And we are slowly iterating on a better solution using gradient descent. We are basically moving down a path to the maximum value point. This is how you can generate output for any given input query. The query might be an image also. Generate an image which looks similar to this image. That can be done. Generate code which looks similar to this code, or generate the code by taking my text query. So you're going to take this text query and have some mechanism to convert that into a vector. The only question which remains is, how are these vectors being generated? When given an image or a piece of code or a video file, how do we map it into a vector space? The answer is a variational auto encoder, which sounds much more complex than it is. This is basically like a compression engine. Given any object, you can hash an object to get a single number, a single value. A variational auto encoder would take the same object and hash it to a value which has some semantic meaning. The idea would be that if you take various images of cats and you run it through a variational auto encoder, the hash value or the final output is going to be such that in the vector space, all the points for cats, n-dimensional points that we generated for cats, are going to be close to each other. The ones for dogs might also be close because they are animals after all. You might have trees quite far apart. And so this variational auto encoder is able to compress the image to its minimum representation. How is it trained? Well, you pass in the image of a cat and then you try to regenerate it. So that's the best test for a compression engine. You pass in the original image and then you try to reconstruct that original image. If you're able to do it in a good way, then you can say that this compression engine is good. The intermediate representation does not lose any information. So the way that these vectors are generated is by using variational auto encoders. The newer models from Google now are doing an end-to-end vector generation. So you don't need to separately train a VAE. You can actually create this diffusion model, this space. And while it is being created, the vectors are also being updated. So this thing is inbuilt into the diffusion training process. So this is what diffusion models look like. They are superior to autoregressive models in terms of their data efficiency. And so they are extensively used when generating images, video, and more recently, code. In future, as we run out of data, as we have lesser and lesser data to work with, to train with, I see diffusion-based models getting even more popularity. They are not more intelligent. They are not smarter than the large-language models that we have today. It's just that their performance, their benchmarks are better. There's a fundamental difference. The internal architecture is not making them smarter. It's just that their performance on the limited benchmarks that we have now are higher. Thank you for watching this. If you have any doubts or suggestions, do let me know in the comments. I'll see you next time. Bye-bye. Recently, I have noticed that there's been a lot of backlash on large-language models. Finally, people are seeing through the hype. But then there is an excuse here. You say that, oh, it was never about the LLMs. It's about the next model, which is going to come in the next five years. This is something we have been seeing for the longest period of time. In 1997, Gary Kasparov lost to a system called Deep Blue by IBM. And everyone thought that the world is ending, because these systems can search in a complicated position. They have heuristics. After all, the world is all about making choices. The search algorithm has been solved. Deep Blue is going to take over the world soon. 28 years later, we are still saying that the world is going to be taken over soon. Lots of things have come. None of them are even close to human intelligence. To be frank with you, I don't see many of these systems even close to mammal-like intelligence. Human intelligence is much, much higher. So if you're concerned that AI is going to be more generally capable than you, is going to be more intelligent than you, it's not going to happen anytime in the near future. People are talking about a decade. I really don't know where they're getting these numbers from. But if you're concerned that AI can take over your job, that depends on the job that you're doing. If you're a doctor, if you're a hotshot lawyer, if you're a top engineer, it's not going to happen anytime soon. But if you're doing something which is mundane, if you're doing something which is repetitive, yourself believe that a lot of this could be automated or is basically pattern matching, then yes, it is likely that AI is going to be either assisting you heavily in your job or it's going to just take over the entire space. The best thing you can do here is to upskill yourself. You can learn more about AI. You can learn more about maybe people. How do you interact with more people and make them more efficient? But don't worry about AGI. This is usually nonsense. Thanks for watching. Cheers.",
  "transcript_length": 13562,
  "synthesis": {
    "raw_text": "**Core Thesis:**\nDiffusion-based models are a new generation of AI models that have surpassed large language models in many tasks, particularly those requiring data efficiency and generative capabilities, such as image, video, and code generation.\n\n**Key Insights:**\n\n* Diffusion-based models generate output by iteratively improving on an initial output through a process of noise addition and refinement, allowing for more flexibility and accuracy than traditional auto-regressive models.\n* The key advantage of diffusion-based models is their ability to handle limited data efficiently, making them particularly useful when working with small datasets or generating new data.\n* Variational Auto Encoders (VAEs) play a crucial role in diffusion-based models by mapping input queries into vector spaces that allow for efficient search and generation of outputs.\n* The internal architecture of diffusion-based models is not inherently more intelligent or capable than large language models, but rather their performance on specific tasks is superior due to their data efficiency and generative capabilities.\n\n**Actionable Takeaways:**\n\n* Consider using diffusion-based models for tasks requiring data efficiency, such as image generation, video generation, or code generation.\n* Train a variational auto encoder (VAE) to enable the use of diffusion-based models in your specific application.\n* Upskill yourself by learning more about AI and machine learning concepts, particularly those related to generative models and vector spaces.\n* Be cautious not to overhype AI's potential for surpassing human intelligence or taking over jobs, and instead focus on understanding its capabilities and limitations.",
    "model_used": "llama3.1:8b",
    "template_used": "basic_summary",
    "transcript_length": 13562,
    "synthesis_length": 1703,
    "use_cloud": false
  },
  "model_used": "llama3.1:8b",
  "template_used": "basic_summary",
  "processing_time": 111.584265,
  "error": null,
  "is_playlist": false,
  "playlist_results": null
}