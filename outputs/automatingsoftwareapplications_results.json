{
  "status": "success",
  "media_file": "https://youtu.be/VDhQFBxIgtI?si=JOV2wzrk4LTIyadN",
  "audio_file": "/var/folders/g1/nd4gy981295dn1ts1pjcb61c0000gn/T/media_knowledge_2ujtcr8o/AI_Agents_Architecture_Usecases__Future_Applicatio_youtube.wav",
  "transcript": "Hi everyone, in this video we'll talk about what AI agents are. This is a very hot topic at the moment because it's got a lot of use cases, a lot of potential, but it's also got a lot of hype. We look at the use cases of agents, we look at what is the internal working of an agent and how it fits into an overall software application. And finally we look at some of the future applications which is driving all the hype. So let's start. Let's take an example where you have a travel agent managing your travel from Mumbai to Bangalore. You mentioned the time when you want to go and the rough location where you need to work. And the travel agent is now expected to come back with some results around flight tickets, around bookings, so hotel bookings and everything else that's related to travel. Now you can write a script around this, but the problem with scripts is they keep changing. For minute changes in requirement, there is a change required in the script which is manual. With the advent of large language models, what's happened is these agents are now smarter. They're able to hit APIs as expected depending on the current situation and the exact requirement. Now how does this behave your benefit companies? Customer success and sales. Both of these use cases have some orchestration with them. When it comes to customer success, if a person comes to you and says, I want to refund all my flight ticket, what you do is you ask them for some details, you send them to the right department and eventually you may accept or reject the request. So some intelligence really improves the chances of good customer satisfaction. So the question is, if you're an engineer or a product manager, when do you decide to go ahead and build an agent? There's five things to consider when you're building an agent. The first is how common is this problem? Does it occur frequently? If that's the case, the investment is likely going to be useful because the number of man hours saved is going to directly convert into profits or more customers. The second thing which is interesting is you're looking for processes which don't have much intelligence, don't have much variation. For example, if you are building a roadmap per customer, you have to go ahead and build a custom roadmap. It makes sense not to give this to a large language model. Maybe it can assist the process, but it can't just take care of it. A complete independent agent may not make sense here, which brings us to our third point, which is low risk. You don't want places where the agent can do a lot of harm. For example, if you're looking for refund queries, yes, the agent can have a bias towards refunding instead of not refunding, where the AI may be too kind to users and accept all claims. It'll directly result in company losses. But if the claim is rejected directly by the AI, that is also risky. So when it comes to a core business problem, which is not related to simple sales, you probably want AI to be out of it. It can assist you in that process, but it can't manage the process by itself. The fourth point is that the number of times a human has to intervene when it comes to this agent should be as low as possible. For example, if a customer comes to your website with a sale query, as long as the large language model can answer it satisfactorily, you want this customer to keep moving ahead in the pipeline and maybe even finish the process of sale. You don't want a human to intervene unless it's necessary, because the whole idea of the agent is to be as independent as you possibly can be and also satisfy customers in a smooth way, not with part bot, part human interaction. And finally, you want this to be low effort. I have seen a lot of people looking at agents as if they can replace humans completely. The reality is that most processes are complex and they require escalation to humans eventually. So what you want to do is you want to maybe manage most of the queries through the bot, but sometimes you have to escalate. Okay, so let's see how these agents actually work in the overall scheme of things. Firstly, you have an LLM agent, which is going to be interacting directly with a large language model. This large language model can be open AI, can be Gemini, can be any large language model that you like. On receiving a query, your agent goes and talks to a vector database, which tries to augment the query with relevant context. For example, a user may be on your website for the past three hours, they may be doing something. When they ask a query, you want that context to be sent with it. How many purchases has the customer already made? What is the last purchase that they made? Do they look for discounts, etc? You also want to add more context to it. So every time a travel agent sends a query to a large language model, it's going to say in the system prompt that you are a travel agent, you are managing bookings for users, blah, blah, blah, just giving the right kind of context that the large language model should think of before responding to it. This often contains the thought process breakdown of this agent. So for example, if you're booking a stay for a person, you're going to be considering flight bookings, you're going to be considering cost, that will be step one, that will be step two, and then you're going to think of a hotel stay step three, and then you're going to think of actually booking that calendar step four. So once you give an example to the large language model, it's able to follow that example and basically recreate the steps in the current situation much better. So the expected response quality is much higher. Now often the large language model is going to respond with certain actions that need to be taken. Here's where your agent shines. It does the actions. Large language models now at this point in time can't perform actions. They still can suggest actions. But with the advent of model context protocol, MCP, these agents can behave like MCP clients. They can actually ask an MCP server to perform actions. So let's say the Airlines Indigo creates an MCP server for booking flights. Your agent can go and talk to that server, ask it to book a flight, maybe take care of the payment also, and come back with a response. So you as a user are going to be happy with your agent because it's managing a lot of things for you. But in reality, it's actually connecting with APIs publicly exposed, which are discovered by the client. Finally, when the response comes back, when the results are in front of you, you as a user may say, wonderful, this is exactly what I wanted. Congratulations. So that's going to be human feedback, which is going to help reinforce good behaviors and demote bad behaviors in this model. So let's say you got the ticket as you expected, but the pricing is really high. You say, no, this is not what I expected. Now the model is going to learn. It's going to say, okay, next time I'll do better. And whether it can pinpoint on the problem of pricing or not is not the problem. It takes a very general brute force approach that, oh, the customer is not happy. I will avoid doing all of the steps that I did last time and try something else next time so that the customer is happier next time. This is called reinforcement learning using human feedback. All right. So that's pretty much it. This is what an agent is. It does look like a MCP wrapper, a rag wrapper, and it does improve its performance based on the feedback that you give it. So if you have any questions or doubts on this, please let me know in the comments. If you liked the video, then do hit the like button. I'll see you next time. Bye-bye. Okay. Now if you want to stick around, I'm going to talk a little bit about the future of these models, the future that I see and I hope to see. One of the things that I really want in these large language models is the ability to perform actions without needing tremendous human intervention. At this point in time, they are, I mean, calling them agents is like a marketing gimmick. It's, they're not agents. They are not independent. They run when told to. So there's a person who's running a script. It feels a lot like a cron job or a workflow file. Okay. A lot of this has exact process. The other thing is that these agents, although they should be improving their performance based on human feedback, don't do it. Right. A lot of the agents which are out there being built by various companies, don't really get better. They just do well enough. And what happens is if a customer says this was bad, then yes, there is an avoidance of the procedure. There's really no learning from it. It's like you get scalded in your hand and then you withdraw and you never want to touch that again. But it's possible that moving till this point was fine. It was touching the pan which scattered you. So the algorithms which are being used to improve these agents are very simple. So the agents themselves are quite dumb. You know, they are like reptiles. They, they can just react. They can't think. Another thing which I see missing here is reasoning. So an agent which is able to reason through simple things, like for example, if you download a ticket after booking it, that will be really helpful. But should I really tell you that? Maybe, maybe, you know, without telling you, it's very hard to reason through this. But the models are at this point in time, not able to look at common use cases and say everything that you should be doing. Yes, but at the same time, you know, I don't want to beat on this too much. The agents which are being built now are useful. They are solving many use cases and they are in hype because they do have a lot of potential. So the name of agents is a marketing image now, but eventually it may be the right name for these, these scripts of code. Thank you again for watching this. If you like AI and if you like system design, do check out interview ready. I've covered various topics of system design, low level design over there. And in fact, the live classes have a lot of white paper readings where we are moving to AI now. So see you next time. Bye bye.",
  "transcript_length": 10186,
  "synthesis": {
    "raw_text": "**Core Thesis**\n\nThe speaker argues that AI agents have the potential to revolutionize software applications by automating repetitive tasks and improving customer satisfaction, but their development requires careful consideration of several key factors.\n\n**Key Insights**\n\n* AI agents can be more effective than traditional scripts in handling complex queries and tasks, especially when they are able to hit APIs as expected based on current situations.\n* There are five key considerations for building an AI agent: how common is the problem it's trying to solve, does the process involve much intelligence or variation, is there low risk involved, can human intervention be minimized, and is the effort required to build the agent low?\n* AI agents typically interact with a large language model (LLM) and use reinforcement learning through human feedback to improve their performance over time.\n* The speaker suggests that current AI agents are more like \"reptiles\" that can react but not think, and that they often don't learn from negative feedback.\n\n**Actionable Takeaways**\n\n* When considering building an AI agent, evaluate the commonality of the problem it's trying to solve and the potential impact on customer satisfaction.\n* Look for processes that involve repetitive tasks or simple queries, where an AI agent can potentially automate a significant amount of work.\n* Use large language models (LLMs) as part of your AI agent architecture, but be aware that they currently lack reasoning capabilities and often require human intervention to correct errors.\n* Design AI agents with reinforcement learning in mind, using human feedback to improve their performance over time.\n* Consider the limitations of current AI agents and plan for future development to address areas such as action-performing capabilities and more sophisticated reasoning.",
    "model_used": "llama3.1:8b",
    "template_used": "basic_summary",
    "transcript_length": 10186,
    "synthesis_length": 1853,
    "use_cloud": false
  },
  "model_used": "llama3.1:8b",
  "template_used": "basic_summary",
  "processing_time": 116.810515,
  "error": null,
  "is_playlist": false,
  "playlist_results": null
}