# Media-to-Knowledge Pipeline Configuration
# Copy this file to .env and fill in your actual values

# Whisper Model Size
# Options: tiny, base, small, medium, large
# Default: small (good balance for M3 Mac)
WHISPER_MODEL_SIZE=small

# Local Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434

# Ollama Cloud Configuration
# NOTE: This URL is a PLACEHOLDER - verify the correct endpoint from official Ollama Cloud documentation
# The actual endpoint may differ from this example
OLLAMA_CLOUD_URL=https://api.ollama.ai/v1

# Ollama Cloud API Key
# Required for cloud authentication
OLLAMA_CLOUD_API_KEY=your_api_key_here

# Ollama Model for Knowledge Synthesis
# Examples: llama3.1:8b, llama3.1:70b, mistral:7b, etc.
OLLAMA_MODEL=llama3.1:8b

# Default Synthesis Prompt Template
# Options: basic_summary, meeting_minutes
DEFAULT_SYNTHESIS_PROMPT_TEMPLATE=basic_summary