#!/usr/bin/env python3
"""
Media-to-Knowledge Pipeline - Main Orchestrator

This script processes video or audio files through a pipeline:
1. Extract/prepare audio from media file
2. Transcribe audio to text using Whisper
3. Synthesize knowledge from transcript using Ollama

Usage:
    python main.py --input /path/to/media.mp4
    python main.py --input /path/to/audio.mp3 --cloud
    python main.py --input /path/to/video.mov --prompt meeting_minutes
"""

import argparse
import json
import sys
import tempfile
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, Any

from core.media_preprocessor import prepare_audio, MediaPreprocessorError
from core.transcriber import transcribe_audio, TranscriberError
from core.synthesizer import KnowledgeSynthesizer, SynthesizerError
from config import get_config


def print_separator(char: str = "=", length: int = 80) -> None:
    """Print a separator line."""
    print(char * length)


def print_section(title: str) -> None:
    """Print a section header."""
    print_separator()
    print(f"\n{title}\n")
    print_separator()


def save_results_to_file(results: Dict[str, Any], output_path: str) -> None:
    """
    Save results to a JSON file.
    
    Args:
        results: Dictionary containing pipeline results.
        output_path: Path to the output file.
    """
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ“ Results saved to: {output_path}")


def save_synthesis_to_markdown(results: Dict[str, Any], output_dir: str = "outputs/markdown") -> None:
    """
    Save synthesized text to a markdown file with subject as filename.
    
    Args:
        results: Dictionary containing pipeline results.
        output_dir: Directory to save markdown files (default: "outputs/markdown").
    """
    if results["status"] != "success" or not results["synthesis"]:
        return
    
    # Create output directory
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Extract synthesis text
    synthesis_text = results["synthesis"]["raw_text"]
    
    # Generate filename from subject (first few words of synthesis)
    # Remove problematic characters and limit length
    first_line = synthesis_text.split('\n')[0].strip('#* ')
    subject = first_line[:50].strip() if first_line else "knowledge_synthesis"
    # Clean filename
    filename = "".join(c for c in subject if c.isalnum() or c in (' ', '-', '_')).rstrip()
    filename = filename.replace(' ', '_').lower()
    # Ensure we have a valid filename
    if not filename or filename.strip() == "":
        filename = "knowledge_synthesis"
    
    # Create markdown content
    md_content = f"""# {subject}

## Source
- File: {results.get('media_file', 'Unknown')}
- Processing Time: {results.get('processing_time', 0):.2f} seconds
- Transcript Length: {results.get('transcript_length', 0):,} characters
- Model Used: {results.get('model_used', 'Unknown')}

## Synthesized Knowledge

{synthesis_text}

---
*Generated by Media-to-Knowledge Pipeline*
"""
    
    # Handle duplicate filenames by adding timestamp
    md_file_path = output_path / f"{filename}.md"
    if md_file_path.exists():
        # Add timestamp for uniqueness
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        md_file_path = output_path / f"{filename}_{timestamp}.md"
    
    with open(md_file_path, 'w', encoding='utf-8') as f:
        f.write(md_content)
    
    print(f"âœ“ Synthesis saved to markdown: {md_file_path}")




def process_media(
    media_path: str,
    use_cloud_synth: bool = False,
    prompt_template: Optional[str] = None,
    custom_prompt: Optional[str] = None
) -> Dict[str, Any]:
    """
    Process a media file through the complete pipeline.
    
    This function orchestrates the entire media-to-knowledge pipeline:
    1. Prepare audio from media file (extract or convert)
    2. Transcribe audio to text using Whisper
    3. Synthesize knowledge from transcript using Ollama
    
    Args:
        media_path: Path to video or audio file.
        use_cloud_synth: Whether to use Ollama Cloud for synthesis.
        prompt_template: Optional prompt template key (e.g., 'meeting_minutes').
        custom_prompt: Optional custom prompt text (overrides prompt_template).
    
    Returns:
        Dictionary containing:
            - status: 'success' or 'error'
            - media_file: Path to input media file
            - audio_file: Path to prepared audio file
            - transcript: Transcribed text
            - transcript_length: Length of transcript
            - synthesis: Synthesized knowledge
            - model_used: Ollama model used
            - template_used: Prompt template used
            - processing_time: Total processing time in seconds
            - error: Error message if status is 'error'
    
    Raises:
        MediaPreprocessorError: If media preprocessing fails.
        TranscriberError: If transcription fails.
        SynthesizerError: If synthesis fails.
    
    Example:
        >>> results = process_media("video.mp4", use_cloud_synth=False)
        >>> print(results["synthesis"]["raw_text"])
    """
    start_time = datetime.now()
    results = {
        "status": "success",
        "media_file": media_path,
        "audio_file": None,
        "transcript": None,
        "transcript_length": 0,
        "synthesis": None,
        "model_used": None,
        "template_used": None,
        "processing_time": 0,
        "error": None
    }
    
    # Create temporary directory for intermediate files
    with tempfile.TemporaryDirectory(prefix="media_knowledge_") as temp_dir:
        try:
            # Step 1: Prepare audio from media file
            print_section("STEP 1: Media Preprocessing")
            print(f"Input file: {media_path}")
            
            audio_path = prepare_audio(media_path, temp_dir)
            results["audio_file"] = audio_path
            print(f"âœ“ Audio prepared: {audio_path}")
            
            # Step 2: Transcribe audio to text
            print_section("STEP 2: Speech-to-Text Transcription")
            
            config = get_config(use_cloud=False)
            transcript = transcribe_audio(
                audio_path,
                model_size=config.whisper_model_size
            )
            results["transcript"] = transcript
            results["transcript_length"] = len(transcript)
            print(f"âœ“ Transcription complete: {len(transcript)} characters")
            
            # Step 3: Synthesize knowledge from transcript
            print_section("STEP 3: Knowledge Synthesis")
            
            synthesizer = KnowledgeSynthesizer(use_cloud=use_cloud_synth)
            
            # Test connection before synthesis
            if not synthesizer.test_connection():
                raise SynthesizerError(
                    f"Cannot connect to Ollama. "
                    f"Ensure Ollama is running: 'ollama serve'"
                )
            
            synthesis_result = synthesizer.synthesize(
                transcript=transcript,
                prompt_template=prompt_template,
                custom_prompt=custom_prompt
            )
            
            results["synthesis"] = synthesis_result
            results["model_used"] = synthesis_result["model_used"]
            results["template_used"] = synthesis_result["template_used"]
            
            print(f"âœ“ Synthesis complete: {synthesis_result['synthesis_length']} characters")
            
        except (MediaPreprocessorError, TranscriberError, SynthesizerError) as e:
            results["status"] = "error"
            results["error"] = str(e)
            print(f"\nâœ— Error: {e}")
            return results
    
    # Calculate total processing time
    end_time = datetime.now()
    processing_time = (end_time - start_time).total_seconds()
    results["processing_time"] = processing_time
    
    return results


def display_results(results: Dict[str, Any]) -> None:
    """
    Display pipeline results in a readable format.
    
    Args:
        results: Dictionary containing pipeline results.
    """
    print_section("PIPELINE RESULTS")
    
    if results["status"] == "error":
        print(f"Status: âœ— Failed")
        print(f"Error: {results['error']}")
        return
    
    print(f"Status: âœ“ Success")
    print(f"Processing Time: {results['processing_time']:.2f} seconds")
    print(f"\nInput File: {results['media_file']}")
    print(f"Audio File: {results['audio_file']}")
    print(f"Transcript Length: {results['transcript_length']:,} characters")
    print(f"Model Used: {results['model_used']}")
    print(f"Template Used: {results['template_used']}")
    
    if results["synthesis"]:
        print_section("SYNTHESIZED KNOWLEDGE")
        print(results["synthesis"]["raw_text"])
    
    print_separator()


def main():
    """Main entry point with CLI interface."""
    parser = argparse.ArgumentParser(
        description="Media-to-Knowledge Pipeline: Extract and synthesize knowledge from video/audio files",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Process a video file with local Ollama
  python main.py --input video.mp4
  
  # Process an audio file with cloud Ollama
  python main.py --input audio.mp3 --cloud
  
  # Use a specific prompt template
  python main.py --input meeting.mp4 --prompt meeting_minutes
  
  # Save results to a JSON file
  python main.py --input lecture.mp4 --output results.json
  
  # Save synthesis to markdown file
  python main.py --input lecture.mp4 --markdown outputs/markdown
  
  # Save both JSON and markdown
  python main.py --input lecture.mp4 --output results.json --markdown outputs/markdown
  
  # Use a custom prompt
  python main.py --input interview.mp4 --prompt "Summarize the key points: {transcript}"
  
  # Scan Downloads directory for media files
  python main.py scan
  
  # Watch Downloads directory for new media files
  python main.py watch
  
  # Scan a custom directory
  python main.py scan --directory /path/to/media
  
  # Watch with custom poll interval
  python main.py watch --interval 10

Available prompt templates:
  basic_summary, meeting_minutes, lecture_summary, tutorial_guide,
  project_update, customer_feedback, research_summary, interview_summary,
  blog_post_outline, social_media_content, technical_documentation, bug_report_summary
        """
    )
    
    # Create subparsers for different modes
    subparsers = parser.add_subparsers(
        dest="command",
        help="Command to execute"
    )
    
    # Process command (original functionality)
    process_parser = subparsers.add_parser(
        "process",
        help="Process a single media file"
    )
    process_parser.add_argument(
        "--input", "-i",
        required=True,
        help="Path to video or audio file to process"
    )
    process_parser.add_argument(
        "--cloud",
        action="store_true",
        help="Use Ollama Cloud for knowledge synthesis (default: local)"
    )
    process_parser.add_argument(
        "--prompt", "-p",
        help="Prompt template key (e.g., 'meeting_minutes') or custom prompt text"
    )
    process_parser.add_argument(
        "--output", "-o",
        help="Optional output file path for results (JSON format)"
    )
    process_parser.add_argument(
        "--markdown", "-m",
        help="Optional directory path for markdown output (default: outputs/markdown)"
    )
    process_parser.add_argument(
        "--quiet", "-q",
        action="store_true",
        help="Suppress detailed output, only show final results"
    )
    
    # Scan command
    scan_parser = subparsers.add_parser(
        "scan",
        help="Scan directory for media files and copy to data directories"
    )
    scan_parser.add_argument(
        "--directory", "-d",
        default="~/Downloads",
        help="Directory to scan (default: ~/Downloads)"
    )
    scan_parser.add_argument(
        "--audio-dir",
        default="data/audio",
        help="Directory for audio files (default: data/audio)"
    )
    scan_parser.add_argument(
        "--video-dir",
        default="data/videos",
        help="Directory for video files (default: data/videos)"
    )
    scan_parser.add_argument(
        "--process",
        action="store_true",
        help="Automatically process copied files through the pipeline"
    )
    scan_parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show what would happen without actually copying files"
    )
    scan_parser.add_argument(
        "--quiet", "-q",
        action="store_true",
        help="Suppress detailed output"
    )
    
    # Watch command
    watch_parser = subparsers.add_parser(
        "watch",
        help="Continuously watch directory for new media files"
    )
    watch_parser.add_argument(
        "--directory", "-d",
        default="~/Downloads",
        help="Directory to watch (default: ~/Downloads)"
    )
    watch_parser.add_argument(
        "--audio-dir",
        default="data/audio",
        help="Directory for audio files (default: data/audio)"
    )
    watch_parser.add_argument(
        "--video-dir",
        default="data/videos",
        help="Directory for video files (default: data/videos)"
    )
    watch_parser.add_argument(
        "--process",
        action="store_true",
        help="Automatically process copied files through the pipeline"
    )
    watch_parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show what would happen without actually copying files"
    )
    watch_parser.add_argument(
        "--interval", "-i",
        type=int,
        default=5,
        help="Poll interval in seconds (default: 5)"
    )
    watch_parser.add_argument(
        "--quiet", "-q",
        action="store_true",
        help="Suppress detailed output"
    )
    
    args = parser.parse_args()
    
    # Handle different commands
    if args.command == "process":
        # Original processing functionality
        _handle_process_command(args)
    elif args.command == "scan":
        # Scan directory for media files
        _handle_scan_command(args)
    elif args.command == "watch":
        # Watch directory for new media files
        _handle_watch_command(args)
    else:
        # Default to process command for backward compatibility
        _handle_process_command(args)


def _handle_process_command(args):
    """Handle the process command (original functionality)."""
    # Validate input file exists
    if not Path(args.input).exists():
        print(f"Error: Input file not found: {args.input}", file=sys.stderr)
        sys.exit(1)
    
    # Print header
    if not args.quiet:
        print_separator()
        print("Media-to-Knowledge Pipeline")
        print_separator()
        print(f"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print_separator()
    
    # Process the media file
    try:
        results = process_media(
            media_path=args.input,
            use_cloud_synth=args.cloud,
            prompt_template=args.prompt if args.prompt and not args.prompt.startswith("Summarize") else None,
            custom_prompt=args.prompt if args.prompt and args.prompt.startswith("Summarize") else None
        )
        
        # Display or save results
        if args.output:
            save_results_to_file(results, args.output)
            if not args.quiet:
                display_results(results)
        elif args.markdown:
            # Save to markdown only
            save_synthesis_to_markdown(results, args.markdown)
            if not args.quiet:
                display_results(results)
        else:
            display_results(results)
        
        # Save to markdown if requested (in addition to JSON)
        if args.markdown and args.output:
            save_synthesis_to_markdown(results, args.markdown)
        
        # Exit with appropriate code
        if results["status"] == "error":
            sys.exit(1)
        else:
            if not args.quiet:
                print(f"\nâœ“ Pipeline completed successfully!")
                print(f"Total processing time: {results['processing_time']:.2f} seconds")
            sys.exit(0)
            
    except KeyboardInterrupt:
        print("\n\nâœ— Pipeline interrupted by user", file=sys.stderr)
        sys.exit(130)
    except Exception as e:
        print(f"\nâœ— Unexpected error: {e}", file=sys.stderr)
        sys.exit(1)


def _handle_scan_command(args):
    """Handle the scan command."""
    try:
        from core.file_scanner import FileScanner
        
        # Print header
        if not args.quiet:
            print_separator()
            print("Media-to-Knowledge Pipeline - File Scanner")
            print_separator()
            print(f"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"Scanning directory: {args.directory}")
            print(f"Audio destination: {args.audio_dir}")
            print(f"Video destination: {args.video_dir}")
            if args.process:
                print("Auto-processing: ENABLED")
            if args.dry_run:
                print("Dry run: ENABLED (no files will be copied)")
            print_separator()
        
        # Define processing callback if auto-process is enabled
        process_callback = None
        if args.process:
            def process_file(file_path):
                if not args.quiet:
                    print(f"Processing file: {file_path.name}")
                
                # Generate output filenames based on input file
                base_name = file_path.stem
                json_output = f"outputs/{base_name}_results.json"
                markdown_dir = "outputs/markdown"
                
                # Use the existing process_media function
                results = process_media(
                    media_path=str(file_path),
                    use_cloud_synth=False,  # Use local by default
                    prompt_template=None
                )
                
                if results["status"] == "success":
                    # Save JSON results
                    save_results_to_file(results, json_output)
                    
                    # Save markdown synthesis
                    save_synthesis_to_markdown(results, markdown_dir)
                    
                    if not args.quiet:
                        print(f"âœ“ Processing completed: {file_path.name}")
                        print(f"  JSON output: {json_output}")
                        print(f"  Markdown output: {markdown_dir}/{base_name}.md")
                else:
                    print(f"âœ— Processing failed: {file_path.name} - {results['error']}")
            
            process_callback = process_file
        
        # Create scanner instance
        scanner = FileScanner(
            scan_directory=args.directory,
            audio_directory=args.audio_dir,
            video_directory=args.video_dir,
            auto_process=args.process,
            process_callback=process_callback,
            dry_run=args.dry_run
        )
        
        # Perform scan
        results = scanner.scan_directory_for_media()
        
        # Display summary
        if not args.quiet:
            print_separator()
            print("SCAN SUMMARY")
            print_separator()
            
            copied_files = [r for r in results if r.status == "copied"]
            dry_run_files = [r for r in results if r.status == "dry_run"]
            skipped_files = [r for r in results if r.status == "skipped"]
            error_files = [r for r in results if r.status == "error"]
            
            print(f"Files processed: {len(results)}")
            if args.dry_run:
                print(f"Files that would be copied: {len(dry_run_files)}")
            else:
                print(f"Files copied: {len(copied_files)}")
            print(f"Files skipped: {len(skipped_files)}")
            print(f"Files with errors: {len(error_files)}")
            
            if copied_files:
                print("\nCopied files:")
                for result in copied_files:
                    print(f"  âœ“ {result.file_path.name} -> {result.destination}")
            
            if dry_run_files:
                print("\nFiles that would be copied (dry run):")
                for result in dry_run_files:
                    print(f"  ðŸ“‹ {result.file_path.name} -> {result.destination}")
            
            if skipped_files:
                print("\nSkipped files (already exist):")
                for result in skipped_files:
                    print(f"  âš  {result.file_path.name}")
            
            if error_files:
                print("\nFiles with errors:")
                for result in error_files:
                    print(f"  âœ— {result.file_path.name}: {result.error_message}")
            
            print_separator()
            if args.dry_run:
                print("âœ“ Dry run completed successfully!")
            else:
                print("âœ“ Scan completed successfully!")
        
        sys.exit(0)
        
    except KeyboardInterrupt:
        print("\n\nâœ— Scan interrupted by user", file=sys.stderr)
        sys.exit(130)
    except Exception as e:
        print(f"\nâœ— Error during scan: {e}", file=sys.stderr)
        sys.exit(1)


def _handle_watch_command(args):
    """Handle the watch command."""
    try:
        from core.file_scanner import FileScanner
        
        # Print header
        if not args.quiet:
            print_separator()
            print("Media-to-Knowledge Pipeline - File Watcher")
            print_separator()
            print(f"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"Watching directory: {args.directory}")
            print(f"Audio destination: {args.audio_dir}")
            print(f"Video destination: {args.video_dir}")
            print(f"Poll interval: {args.interval} seconds")
            if args.process:
                print("Auto-processing: ENABLED")
            if args.dry_run:
                print("Dry run: ENABLED (no files will be copied)")
            print_separator()
            print("Press Ctrl+C to stop watching")
            print_separator()
        
        # Define processing callback if auto-process is enabled
        process_callback = None
        if args.process:
            def process_file(file_path):
                if not args.quiet:
                    print(f"Processing file: {file_path.name}")
                
                # Generate output filenames based on input file
                base_name = file_path.stem
                json_output = f"outputs/{base_name}_results.json"
                markdown_dir = "outputs/markdown"
                
                # Use the existing process_media function
                results = process_media(
                    media_path=str(file_path),
                    use_cloud_synth=False,  # Use local by default
                    prompt_template=None
                )
                
                if results["status"] == "success":
                    # Save JSON results
                    save_results_to_file(results, json_output)
                    
                    # Save markdown synthesis
                    save_synthesis_to_markdown(results, markdown_dir)
                    
                    if not args.quiet:
                        print(f"âœ“ Processing completed: {file_path.name}")
                        print(f"  JSON output: {json_output}")
                        print(f"  Markdown output: {markdown_dir}/{base_name}.md")
                else:
                    print(f"âœ— Processing failed: {file_path.name} - {results['error']}")
            
            process_callback = process_file
        
        # Create scanner instance
        scanner = FileScanner(
            scan_directory=args.directory,
            audio_directory=args.audio_dir,
            video_directory=args.video_dir,
            auto_process=args.process,
            process_callback=process_callback,
            dry_run=args.dry_run
        )
        
        # Define callback for file processing
        def on_file_processed(result):
            if not args.quiet:
                if result.status == "copied":
                    print(f"âœ“ Copied {result.file_type} file: {result.file_path.name}")
                elif result.status == "dry_run":
                    print(f"ðŸ“‹ Would copy {result.file_type} file: {result.file_path.name}")
                elif result.status == "skipped":
                    print(f"âš  Skipped {result.file_type} file: {result.file_path.name}")
                else:
                    print(f"âœ— Error processing {result.file_type} file: {result.file_path.name}")
        
        # Start watching
        scanner.watch_directory(
            callback=on_file_processed,
            poll_interval=args.interval
        )
        
    except KeyboardInterrupt:
        print("\n\nâœ“ Watch mode stopped by user")
        sys.exit(0)
    except Exception as e:
        print(f"\nâœ— Error in watch mode: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()